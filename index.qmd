---
title: "Syntesis of calibration plots"
author: "Munoz, Debray & de Jong <br>May 1st, 2023"

format: 
  revealjs:
    slide-number: true
    logo: images/logo.png
    css: images/logo.css
    theme: default
    preview-links: auto
    chalkboard: 
      boardmarker-width: 5
from: markdown+emoji
execute:
  echo: false
editor: visual
---

## Today's presentation

<br/>

::: incremental
1.  What is a calibration plot?
2.  Issues with multiple source information
3.  Methods
4.  Simulation
:::

## Prediction model

::: columns
::: {.column width="60%"}
::: fragment
$$y \sim \beta_0+ \beta_1X$$ $$ ln\left(\frac{\pi}{1-\pi}\right)=\beta_0+ \beta_1X$$
:::

::: fragment
[Calibration:]{style="color:#007FFF"}
:::

::: fragment
Agreement between the prediction risk '$\pi$' and the observed proportion of the outcome '$y$'
:::
:::

::: {.column width="40%"}
::: fragment
![Model prediction output (Calibration in large)](images/mod_pred.png){fig-align="right"}
:::
:::
:::

## Calibration plot

::: columns
::: {.column width="30%"}
Group $\pi$ in bins ![](images/bin_prop.png){fig-align="left"}
:::

::: {.column width="70%"}
```{r fig.width=6, fig.height=6}
df <- data.frame(pi=seq(0.1,0.9,0.1),
                 n = c(2,12,10,10,10,15,14,16,11),
                 ny =c(0,2,3,2,5,11,8,12,11))
df$prop<-df$ny/df$n
library(ggplot2)
ggplot(df,aes(x=pi,y=prop))+
  geom_point(color="blue", size=2)+
  geom_line(color="blue")+
  geom_abline(linetype="dashed")+
  theme_light()+
  xlab(expression("Mean predicted value"~(pi)))+ylab("Observed proportion (y=1)")
  
```
:::
:::

:::

## Multiple sources of information

::: columns
::: {.column width="30%"}
![](images/mclust.png){width="80%"}
:::

::: {.column width="70%"}
::: fragment
-   Multiple imputation:

    Cluster = completed data set
:::

::: fragment
-   Individual patient data (IPD):

    Cluster = study data set
:::
:::
:::

## Overall calibration curve

::: columns
::: {.column width="30%"}
![](images/mclust.png){width="80%"}
:::

::: {.column width="70%"}
::: fragment
```{r fig.width=6, fig.height=6}
df <- data.frame(pi=seq(0.1,0.9,0.1),
                 n = c(2,12,10,10,10,15,14,16,11),
                 ny1 =c(0,1,3,2,5,11,8,12,11),
                 ny2 =c(0.1,3,3,NA,NA,NA,NA,NA,NA),
                 nyk = c(0,0,0,0,0,0,14,16,11))
df$prop1<-df$ny1/df$n
df$prop2<-df$ny2/df$n
df$propk<-df$nyk/df$n

dn<-data.frame(cluster=rep(c("1","2","K"),each=9),
               pi=rep(df$pi,3),
               prop=c(df$prop1,df$prop2,df$propk))

ggplot(dn,aes(x=pi,y=prop))+
  geom_point(aes(color=cluster), size=2)+
  geom_line(aes(color=cluster))+
  geom_abline(linetype="dashed")+
  theme_light()+
  xlab(expression("Mean predicted value"~(pi)))+ylab("Observed proportion (y=1)")+
  scale_color_manual(values=c("#99CCFF", "#99CC99","#FFCC66"))+
  scale_fill_manual(values=c("#99CCFF", "#99CC99","#FFCC66"))

  
```
:::
:::
:::

:::

## Overall calibration curve

::: columns
::: {.column width="30%"}
![](images/mclust.png){width="80%"}
:::

::: {.column width="70%"}
```{r fig.width=6, fig.height=6}
df <- data.frame(pi=seq(0.1,0.9,0.1),
                 n = c(2,12,10,10,10,15,14,16,11),
                 ny1 =c(0,1,3,2,5,11,8,12,11),
                 ny2 =c(0.1,3,3,NA,NA,NA,NA,NA,NA),
                 nyk = c(0,0,0,0,0,0,14,16,11))
df$prop1<-df$ny1/df$n
df$prop2<-df$ny2/df$n
df$propk<-df$nyk/df$n

dn<-data.frame(cluster=rep(c("1","2","K"),each=9),
               pi=rep(df$pi,3),
               prop=c(df$prop1,df$prop2,df$propk))

ggplot(dn,aes(x=pi,y=prop))+
  geom_abline(linetype="dashed")+
  theme_light()+
  xlab(expression("Mean predicted value"~(pi)))+ylab("Observed proportion (y=1)")+
  scale_color_manual(values=c("#99CCFF", "#99CC99","#FFCC66"))+
  scale_fill_manual(values=c("#99CCFF", "#99CC99","#FFCC66"))+
  geom_smooth(aes(color = cluster, fill = cluster)) 
  
```
:::
:::

::: ::: :::

## Overall calibration curve (Average)

::: columns
::: {.column width="30%"}
![](images/mclust.png){width="80%"}
:::

::: {.column width="70%"}
```{r fig.width=6, fig.height=6}
df <- data.frame(pi=seq(0.1,0.9,0.1),
                 n = c(2,12,10,10,10,15,14,16,11),
                 ny1 =c(0,1,3,2,5,11,8,12,11),
                 ny2 =c(0.1,3,3,NA,NA,NA,NA,NA,NA),
                 nyk = c(0,0,0,0,0,0,14,16,11))
df$prop1<-df$ny1/df$n
df$prop2<-df$ny2/df$n
df$propk<-df$nyk/df$n

dn<-data.frame(cluster=rep(c("1","2","K"),each=9),
               pi=rep(df$pi,3),
               prop=c(df$prop1,df$prop2,df$propk))

ggplot(dn,aes(x=pi,y=prop))+
  geom_abline(linetype="dashed")+
  theme_light()+
  xlab(expression("Mean predicted value"~(pi)))+ylab("Observed proportion (y=1)")+
  scale_color_manual(values=c("#99CCFF", "#99CC99","#FFCC66"))+
  scale_fill_manual(values=c("#99CCFF", "#99CC99","#FFCC66"))+
  geom_smooth(aes(color = cluster, fill = cluster))+
  geom_smooth(mapping = aes(x =pi, y = prop), linetype=2, se=FALSE, color="Purple")
  
```
:::
:::

::: ::: :::

## Overall calibration curve (SE)

::: columns
::: {.column width="30%"}
![](images/mclust.png){width="80%"}
:::

::: {.column width="70%"}
```{r fig.width=6, fig.height=6}
df <- data.frame(pi=seq(0.1,0.9,0.1),
                 n = c(2,12,10,10,10,15,14,16,11),
                 ny1 =c(0,1,3,2,5,11,8,12,11),
                 ny2 =c(0.1,3,3,NA,NA,NA,NA,NA,NA),
                 nyk = c(0,0,0,0,0,0,14,16,11))
df$prop1<-df$ny1/df$n
df$prop2<-df$ny2/df$n
df$propk<-df$nyk/df$n

dn<-data.frame(cluster=rep(c("1","2","K"),each=9),
               pi=rep(df$pi,3),
               prop=c(df$prop1,df$prop2,df$propk))

ggplot(dn,aes(x=pi,y=prop))+
  geom_abline(linetype="dashed")+
  theme_light()+
  xlab(expression("Mean predicted value"~(pi)))+ylab("Observed proportion (y=1)")+
  scale_color_manual(values=c("#99CCFF", "#99CC99","#FFCC66"))+
  scale_fill_manual(values=c("#99CCFF", "#99CC99","#FFCC66"))+
  geom_smooth(aes(color = cluster, fill = cluster))+
  geom_smooth(mapping = aes(x =pi, y = prop), linetype=2, se=TRUE, color="Purple")
  
```
:::
:::

::: :::

## Methods

-   Stacked
-   Agregated by ID
-   Model based
-   Bootstrapp

## Stacked

![](images/stack.png){width="150%"}

## Agregated by ID

![](images/modid.png){width="150%"}

## Model based 1-step

![](images/mod1s.png){width="150%,height=150%"}

## Model based 2-step (Multivariate)

![](images/mod2m.png){width="120%,height=120%"}

## Model based 2-step (Point-wise)

![](images/mod2p.png){width="150%"}

## Boot-strap

![](images/boot.png){width="150%"}

## Simulation

::: fragment
[Aim:]{style="color:#007FFF"}
:::

::: fragment
Evaluate the performance of these methods
:::

::: fragment
[Data generation:]{style="color:#007FFF"}
:::

::: fragment
-   Multiple imputation
:::

::: fragment
-   IPD ($\pi$ range variation)
:::

## Simulation

::: fragment
[Performance measures:]{style="color:#007FFF"}
:::

::: fragment
[1. Marginal metrics:]{style="color:#99CCFF"}

\- ICI (bias)

\- e50, e90, emax

\- Coverage
:::

::: fragment
[2. Conditional metrics $f(\pi)$:]{style="color:#99CCFF"}

\- Bias

\- Length of the confidence interval

\- Coverage
:::
