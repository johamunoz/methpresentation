---
format: 
  revealjs:
    slide-number: true
    # preview-links: true
    code-link: true
    highlight-style: a11y
    chalkboard: true
    # self-contained: true
    # scrollable: true
    logo: images\logo.png
    theme: 
      - theme.scss
---

<br> <br>

<hr>

[Synthesis of calibration plots]{.custom-title}

<hr>

<br> <br>

[Munoz, Debray & de Jong]{.custom-subtitle}

Julius Center, Epi Methods group

------------------------------------------------------------------------

[{{< fa check >}} Motivation]{.slide-title}

<hr>

::: incremental
-   Literature enhance the use of calibration plot over discrete measures(Austin 2014).
-   Available package to get calibration plots (rms,calibration).
-   The synthesis of calibration plots coming from different source of information (**Clusters**).
:::

------------------------------------------------------------------------

[{{< fa check >}} Calibration plots from clusters]{.slide-title}

```{r}
#| echo: false
library(ggplot2)
load("images/dataplot1.Rdata")
load("images/sdata1.Rdata")
```

```{r fig.width=12, fig.height=6}
ggplot(data = dataplot, aes(x = pi, y =pr,color=as.factor(cluster))) +
  theme_light()+
  geom_ribbon(aes(ymin = Lpr, ymax = Upr), fill = "lightgray",alpha = .3, colour = NA)+ 
  geom_abline(color="black",linetype="dashed")+
  geom_line(color="#047C90")+
  facet_wrap(~cluster,ncol=10)+
  labs( x =expression("Estimated probability"~(pi)),
        y = "Empirical probability")+
  theme(legend.position="none")+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))
```
------------------------------------------------------------------------

[{{< fa check >}} Calibration plots from clusters]{.slide-title}

```{r fig.width=10, fig.height=6}
ggplot(data = dataplot) +
  theme_light()+
  geom_line(aes(x = pi, y = pr,group=cluster),color="#047C90",alpha=0.2)+
  labs( x =expression("Estimated probability"~(pi)),
        y = "Actual proportion")+
  theme(legend.position="none")+
  geom_line(data=sdata,aes(x,y),size=1.5,color="#003660")+
  geom_abline(color="black",linetype="dashed")+
   labs( x =expression("Estimated probability"~(pi)),
        y = "Empirical probability")+
  theme(legend.position="none")
```

------------------------------------------------------------------------

[{{< fa check >}} Calibration plots from clusters]{.slide-title}

```{r fig.width=10, fig.height=6}
ggplot(data = dataplot) +
  theme_light()+
    geom_line(aes(x = pi, y = pr,group=cluster),color="#047C90",alpha=0.2)+
  labs( x =expression("Estimated probability"~(pi)),
        y = "Actual proportion")+
  theme(legend.position="none")+
  geom_ribbon(data=sdata,aes(x=x,ymax=ymax,ymin=ymin), fill = "#ADADAD")+
  geom_line(data=sdata,aes(x,y),size=1.5,color="#003660")+
  geom_abline(color="black",linetype="dashed")+
   labs( x =expression("Estimated probability"~(pi)),
        y = "Empirical probability")+
  theme(legend.position="none")
```

------------------------------------------------------------------------

[{{< fa check >}} Context]{.slide-title}
![](images/m1.png)

------------------------------------------------------------------------

[{{< fa check >}} Context]{.slide-title}
![](images/m2.png)

------------------------------------------------------------------------

[{{< fa check >}} Context]{.slide-title}
![](images/m3.png)

------------------------------------------------------------------------

[{{< fa check >}} Context]{.slide-title}
![](images/m4.png)

------------------------------------------------------------------------

[{{< fa check >}} Context]{.slide-title}
![](images/m5.png)

------------------------------------------------------------------------

[{{< fa check >}} Context]{.slide-title}
![](images/m6.png)

------------------------------------------------------------------------

[{{< fa check >}} Context]{.slide-title}
![](images/cl1.png)

------------------------------------------------------------------------

[{{< fa check >}} Context]{.slide-title}
![](images/cl2.png)

------------------------------------------------------------------------

[{{< fa check >}} Multiple Imputation]{.slide-title}

<hr>
**Aim:**
Evaluate methods for synthesize the calibration curves derived from multiple imputation output or from individual participant data in terms of coverage, CI length and bias. We focus on:

::: incremental
-   Smoothed calibration curves.
-   Smooth functions : Loess, Locfit, natural splines.
-   Confidence intervals: Closed form, Bootstrap.
:::

------------------------------------------------------------------------

[{{< fa check >}} Data generation]{.slide-title}
![](images/d1.png)

------------------------------------------------------------------------

[{{< fa check >}} Data generation]{.slide-title}
![](images/d2.png)

------------------------------------------------------------------------

[{{< fa check >}} Data generation]{.slide-title}
![](images/d3.png)

------------------------------------------------------------------------

[{{< fa check >}} Data generation]{.slide-title}
![](images/d4.png)

------------------------------------------------------------------------

[{{< fa check >}} Data generation]{.slide-title}
![](images/d5.png)
------------------------------------------------------------------------

[{{< fa check >}} Methods]{.slide-title}

<hr>

+------------------------------+---------------------------------------+------------+------------+
| Type                         | Method                                | MI         | BT         |
+==============================+=======================================+============+============+
| Multiple imputation only (m) | -   Stack.                            | 10         |            |
|                              | -   Model pooled parameters (RRPar).  |            |            |
|                              | -   Pooled se closed form (RR).       |            |            |
+------------------------------+---------------------------------------+------------+------------+
| MI then Bootstrap (mb)       | -   Rubins rules (RR).                | 10         | 1000       |
|                              | -   Percentile Quartiles (Q).         |            |            |
+------------------------------+---------------------------------------+------------+------------+
| Bootstrap then MI (bm)       | -   Percentile pooled Quartiles (Qp). | -   10     | 1000       |
|                              | -   Percentile total Quartiles (Qt).  | -   10     |            |
|                              | -   Single quartile (Q1).             | -   1      |            |
|                              | -   Von Hippel (VH).                  | -   2      |            |
+------------------------------+---------------------------------------+------------+------------+

------------------------------------------------------------------------

[{{< fa check >}} Performance measurements]{.slide-title}

<hr>

Across 100 percentiles

-   CI length
-   Bias (median).
-   Coverage (median, number of points in 95%CI coverage).

------------------------------------------------------------------------

[{{< fa check >}} Conditional results]{.slide-title}
 ![](images/Cond.png)

------------------------------------------------------------------------

[{{< fa check >}} Marginal results: CI length]{.slide-title}
![](images/medCIL2.png)

------------------------------------------------------------------------

[{{< fa check >}} Marginal results: Bias]{.slide-title}
![](images/meanbias2.png)

------------------------------------------------------------------------

[{{< fa check >}} Marginal results: Coverage]{.slide-title}
![](images/mediancov.png)

------------------------------------------------------------------------

[{{< fa check >}} Marginal results: Rank]{.slide-title}
![](images/rank.png)

------------------------------------------------------------------------

[{{< fa check >}} Conclusion]{.slide-title}

<hr>

::: incremental
-   Not an overall winner method in coverage or bias.
-   Bootstrap and then MI methods provide more points inside the 95%CI coverage.
-   Single BS-MI alternative considering time processing.
:::

------------------------------------------------------------------------

[{{< fa check >}} References]{.slide-title}

<hr>

1.  Austin PC, Steyerberg EW. Graphical assessment of internal and external calibration of logistic regression models by using loess smoothers. Stat Med. 2014; 33(3): 517-535.
2.  Harrell FE Jr. Regression Modeling Strategies. 2nd ed. New York, NY: Springer-Verlag; 2015.
3.  Schomaker, M., & Heumann, C. (2018). Bootstrap inference when using multiple imputation. Statistics in medicine, 37(14), 2252-2266.
4.  Bartlett, J. W., & Hughes, R. A. (2020). Bootstrap inference for multiple imputation under uncongeniality and misspecification. Statistical methods in medical research, 29(12), 3533-3546.
 
------------------------------------------------------------------------





